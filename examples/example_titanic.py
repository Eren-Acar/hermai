# examples/example_titanic.py

import pandas as pd
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Import our Hermai library
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from hermai.perturbations import TabularPerturbationGenerator
from hermai.core.explainer import HermaiExplainer

# 1. LOAD AND PREPARE THE DATASET
print("ðŸš¢ Loading and preparing the Titanic dataset...")
df = sns.load_dataset('titanic')

# Simple data cleaning and feature engineering
df.drop(['deck', 'embark_town', 'alive'], axis=1, inplace=True)
df['age'].fillna(df['age'].median(), inplace=True)
df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)
df.dropna(inplace=True)

# Convert categorical features to a numerical format
encoders = {}
for col in ['sex', 'embarked', 'class', 'who', 'adult_male', 'alone']:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    encoders[col] = le

X = df.drop('survived', axis=1)
y = df['survived']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# 2. TRAIN A MACHINE LEARNING MODEL
print("\nðŸ¤– Training a RandomForestClassifier model...")
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
print(f"   - Model accuracy on test set: {model.score(X_test, y_test):.2f}")


# 3. INITIALIZE THE HERMAI EXPLAINER
print("\nðŸ”¬ Initializing the Hermai Perturbation Engine...")
original_categorical_features = ['sex', 'pclass', 'embarked', 'class', 'who', 'adult_male', 'alone']
tabular_generator = TabularPerturbationGenerator(categorical_features=original_categorical_features)
tabular_generator.fit(X_train)
explainer = HermaiExplainer(model, tabular_generator)


# 4. SELECT AN INSTANCE TO EXPLAIN
print("\nðŸ§ Selecting an instance to explain...")
# Let's pick a passenger who did not survive but the case is not obvious
instance_to_explain = X_test.iloc[0]
instance_label = y_test.iloc[0]
prediction_prob = model.predict_proba(instance_to_explain.to_frame().T)[0, 1]
prediction = 1 if prediction_prob > 0.5 else 0

print("\n--- Original Passenger Details ---")
print(instance_to_explain)
print(f"\nActual Outcome: {'Survived' if instance_label == 1 else 'Did not survive'}")
print(f"Model Prediction: {'Will survive' if prediction == 1 else 'Will not survive'} (Confidence: {prediction_prob:.2%})")
print("----------------------------------\n")


# 5. GENERATE THE FULL EXPLANATION
explanation = explainer.explain_instance(instance_to_explain, n_samples=3000)


# 6. INTERPRET THE FULL EXPLANATION FROM THE EXPLANATION OBJECT
print("\n\n" + "="*50)
print("              HERMAI EXPLANATION REPORT")
print("="*50 + "\n")

# Print the narrative generated by Module 4
print(explanation.to_text())

# Show the visualization generated by Module 4
print("\n--- Feature Importance Plot ---")
explanation.plot_feature_importance()